{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit72a75e54b0294944b34ebbde9c9c68ed",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train = load_files(r'D:\\ML_TextMining\\data_inspire\\inspire-train', shuffle=True, encoding='utf-8', random_state=42)\n",
    "meta_test = load_files(r'D:\\ML_TextMining\\data_inspire\\inspire-test', shuffle=True, encoding='utf-8', random_state=42)\n",
    "\n",
    "X_train = meta_train.data\n",
    "y_train = meta_train.target\n",
    "X_test = meta_test.data\n",
    "y_test = meta_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"german_stopwords_plain.txt\")\n",
    "stopwords = df.loc[:,'#german_stopwords_plain.txt'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "CountVectorizer Shape: (72, 1677)\n"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words=stopwords)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "print('CountVectorizer Shape:', X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Test-Label True: [ 8 12  6 23 12 12 12 12]\nTest-Label Pred: [ 8 23 17 23 12 12  7 23]\nTest Score: 0.5\nTrain Score: 0.9166666666666666\n\nZuordnung Test-Dokumente:\n'Keywords:\\r\\nGeologie, Geologische Einheiten, Geologische Übersichtskarte 1:250.000, Karte, Vectordaten\\r\\n\\r\\nTypes:\\r\\ngeologische Karte 250000\\r\\n\\r\\nDesc:\\r\\nGeologische Karte 1:250 000:\\r\\nDie Geologische Karte 1:250 000 liegt digital vor. Sie wird laufend aktualisiert, als Geodatendienst veröffentlicht und gegebenenfalls in digitaler Form auch auf CD abgegeben.\\r\\n\\r\\nAnsprechpartner:\\r\\nBehörde für Umwelt und Energie (BUE)\\r\\nWasser, Abwasser und Geologie (W)\\r\\nGeologisches Landesamt\\r\\nGrundsatz, Geowissenschaftliche Landesaufnahme' => ge \n\n'Keywords:\\r\\nSpielplatz, Kinderspielplatz, Spielen, Point, Vectordaten\\r\\n\\r\\nTypes:\\r\\nspielplatz\\r\\n\\r\\nDesc:\\r\\nStandorte von Spielplätzen in Hamburg.\\r\\n\\r\\nAnsprechpartner:\\r\\n' => us-gov \n\n'Keywords:\\r\\nWasserkraftwerk, Wasserkraft, Energieerzeugung, Turbine, Point, Vectordaten\\r\\n\\r\\nTypes:\\r\\nwasserkraftwerk\\r\\n\\r\\nDesc:\\r\\nStandorte von Wasserkraftwerken in Hamburg\\r\\n\\r\\nAnsprechpartner:\\r\\nBehörde für Umwelt und Energie (BUE)' => ps \n\n'Keywords:\\r\\nBehörde, Behördenstandort, Verwaltung, Verwaltungsdienstleistung, Bürgerservice, Point, Vectordaten\\r\\n\\r\\nTypes:\\r\\nbehoerden\\r\\n\\r\\nDesc:\\r\\nStandorte von Behörden in Hamburg.\\r\\n\\r\\nAnsprechpartner:\\r\\nLGV' => us-gov \n\n'Keywords:\\r\\nAmpel, Verkehr, Verkehrssteuerung, Point, Vectordaten\\r\\n\\r\\nTypes:\\r\\nampeln\\r\\n\\r\\nDesc:\\r\\nAmpeln, Lichtsignalanlagen in Hamburg.\\r\\n\\r\\nAnsprechpartner:\\r\\n' => not_inspire \n\n'Keywords:\\r\\nSensor, Parkraumsensor, Strassenverkehr, Parken, Point, Vectordaten\\r\\n\\r\\nTypes:\\r\\nparkraumsensor\\r\\n\\r\\nDesc:\\r\\nStandorte von Parkraumsensoren in Hamburg.\\r\\n\\r\\nAnsprechpartner:\\r\\n' => not_inspire \n\n'Keywords:\\r\\nUntergrund, Temperatur, Teufe, temperatur in 200 m unter gelände, Polygon, Vectordaten\\r\\n\\r\\nTypes:\\r\\ntemperatur in 200 m unter gelaende\\r\\n\\r\\nDesc:\\r\\nTemperatur in 200 m unter Gelände:\\r\\nKarte zur Temperaturverteilung in einer Tiefe von 200 m unter Gelände.\\r\\n\\r\\nDatengrundlage sind gemessene Temperaturprofile an ca. 130 tiefen Grundwassermessstellen. Diese Temperaturprofile dienen als Grundlage für die Konstruktion und Interpolation (Kriging) eines 3D Temperaturmodells für den mitteltiefen Untergrund Hamburgs (Damerau, 2013). Mit Hilfe des Temperaturmodells wurde eine Flächenkarte der natürlichen Temperaturverteilung in der Tiefe von 200 m unter Gelände entwickelt.\\r\\n\\r\\nAnsprechpartner:\\r\\nBehörde für Umwelt und Energie (BUE)\\r\\nWasser, Abwasser und Geologie (W)\\r\\nGeologisches Landesamt\\r\\nAngewandte Geowissenschaften - Information und Beratung' => er-c \n\n'Keywords:\\r\\nSportplatz, Sport, Point, Vectordaten\\r\\n\\r\\nTypes:\\r\\nsportplatz\\r\\n\\r\\nDesc:\\r\\nStandorte von Sportplätzen in Hamburg.\\r\\n\\r\\nAnsprechpartner:\\r\\nLGV' => us-gov \n\n\nKlassifikations Report Testdaten:\n              precision    recall  f1-score   support\n\n           6       0.00      0.00      0.00         1\n           7       0.00      0.00      0.00         0\n           8       1.00      1.00      1.00         1\n          12       1.00      0.40      0.57         5\n          17       0.00      0.00      0.00         0\n          23       0.33      1.00      0.50         1\n\n    accuracy                           0.50         8\n   macro avg       0.39      0.40      0.35         8\nweighted avg       0.79      0.50      0.54         8\n\n\nKlassifikations Report Trainingsdaten:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         1\n           1       1.00      1.00      1.00         5\n           2       0.50      1.00      0.67         2\n           3       0.00      0.00      0.00         1\n           4       0.00      0.00      0.00         1\n           5       1.00      1.00      1.00         1\n           6       0.00      0.00      0.00         1\n           7       1.00      1.00      1.00         6\n           8       1.00      1.00      1.00         3\n           9       1.00      1.00      1.00         3\n          10       1.00      1.00      1.00         1\n          11       0.60      1.00      0.75         3\n          12       0.90      1.00      0.95         9\n          13       1.00      1.00      1.00         1\n          14       1.00      1.00      1.00         1\n          15       0.67      1.00      0.80         2\n          16       1.00      1.00      1.00         3\n          17       1.00      1.00      1.00        10\n          18       1.00      1.00      1.00         1\n          19       1.00      1.00      1.00         2\n          20       1.00      0.50      0.67         2\n          21       1.00      0.33      0.50         3\n          22       1.00      1.00      1.00         3\n          23       1.00      1.00      1.00         7\n\n    accuracy                           0.92        72\n   macro avg       0.82      0.83      0.81        72\nweighted avg       0.91      0.92      0.90        72\n\n"
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(X_test)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "\n",
    "print('Test-Label True:', y_test)\n",
    "print('Test-Label Pred:', predicted)\n",
    "print('Test Score:', clf.score(X_test_counts, y_test))\n",
    "print('Train Score:', clf.score(X_train_counts, y_train))\n",
    "\n",
    "print('\\nZuordnung Test-Dokumente:')\n",
    "category = meta_test.target_names\n",
    "for doc, category in zip(X_test, predicted):\n",
    "    print('%r => %s' % (doc, meta_test.target_names[category]), '\\n')\n",
    "\n",
    "#probability test-documents for class:\n",
    "df_proba = pd.DataFrame(clf.predict_proba(X_test_counts))\n",
    "df_proba.to_csv(r\"D:\\ML_TextMining\\probability_nb_document.csv\", sep=';', index=True)\n",
    "\n",
    "print('\\nKlassifikations Report Testdaten:')\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print('\\nKlassifikations Report Trainingsdaten:')\n",
    "print(metrics.classification_report(y_train, clf.predict(X_train_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nWahrscheinlichkeitsverhaeltnis us-gov : rest [Zeile 25]\n     behörde  verwaltung  point  vectordaten   Summe  p_behörde  p_verwaltung  \\\n23      7.0         1.0    7.0          7.0   226.0   0.030973      0.004425   \n24     44.0         6.0   10.0         55.0  4613.0   0.009538      0.001301   \n25      NaN         NaN    NaN          NaN     NaN   3.247285      3.401917   \n\n      p_point  p_vectordaten  \n23   0.030973       0.030973  \n24   0.002168       0.011923  \n25  14.288053       2.597828  \n\nChance us-gov pos: 17.395690064397407\nproba us-gov pos: 0.9456394407331652\n"
    }
   ],
   "source": [
    "#Exkurs Wahrscheinlichkeiten am Beispiel Test-Dokument 'Behoerden' der Klasse us-gov:\n",
    "dfc = pd.DataFrame(clf.feature_count_, columns=count_vect.get_feature_names())\n",
    "dfc.loc[:,'Summe'] = dfc.sum(axis=1)\n",
    "dfc.loc[24] = dfc.loc[dfc.index.difference([23])].sum(axis=0)\n",
    "dfd = dfc.loc[[23,24],['behörde','verwaltung','point','vectordaten','Summe']]\n",
    "\n",
    "dfd.loc[:,'p_behörde'] = dfd.loc[:,'behörde'] / dfd.loc[:,'Summe']\n",
    "dfd.loc[:,'p_verwaltung'] = dfd.loc[:,'verwaltung'] / dfd.loc[:,'Summe']\n",
    "dfd.loc[:,'p_point'] = dfd.loc[:,'point'] / dfd.loc[:,'Summe']\n",
    "dfd.loc[:,'p_vectordaten'] = dfd.loc[:,'vectordaten'] / dfd.loc[:,'Summe']\n",
    "\n",
    "dfd.loc[25,'p_behörde'] = dfd.loc[23,'p_behörde'] / dfd.loc[24,'p_behörde']\n",
    "dfd.loc[25,'p_verwaltung'] = dfd.loc[23,'p_verwaltung'] / dfd.loc[24,'p_verwaltung']\n",
    "dfd.loc[25,'p_point'] = dfd.loc[23,'p_point'] / dfd.loc[24,'p_point']\n",
    "dfd.loc[25,'p_vectordaten'] = dfd.loc[23,'p_vectordaten'] / dfd.loc[24,'p_vectordaten']\n",
    "\n",
    "r = 7/165 * dfd.loc[25,'p_behörde'] * dfd.loc[25,'p_verwaltung'] * dfd.loc[25,'p_point'] * dfd.loc[25,'p_vectordaten']\n",
    "\n",
    "print('\\nWahrscheinlichkeitsverhaeltnis us-gov : rest [Zeile 25]\\n', dfd)\n",
    "print('\\nChance us-gov pos:', r)\n",
    "print('proba us-gov pos:', r/(r+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "True: [ 8 12  6 23 12 12 12 12]\nPred: [ 8 23 17 12 12 12  7 12]\nScore Test: 0.5\nScore Train 0.5416666666666666\n\nKlassifikations Report Testdaten:\n              precision    recall  f1-score   support\n\n           6       0.00      0.00      0.00         1\n           7       0.00      0.00      0.00         0\n           8       1.00      1.00      1.00         1\n          12       0.75      0.60      0.67         5\n          17       0.00      0.00      0.00         0\n          23       0.00      0.00      0.00         1\n\n    accuracy                           0.50         8\n   macro avg       0.29      0.27      0.28         8\nweighted avg       0.59      0.50      0.54         8\n\n\nKlassifikations Report Trainingsdaten:\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       1.00      0.60      0.75         5\n           2       0.00      0.00      0.00         2\n           3       0.00      0.00      0.00         1\n           4       0.00      0.00      0.00         1\n           5       0.00      0.00      0.00         1\n           6       0.00      0.00      0.00         1\n           7       1.00      1.00      1.00         6\n           8       1.00      1.00      1.00         3\n           9       1.00      0.33      0.50         3\n          10       0.00      0.00      0.00         1\n          11       0.00      0.00      0.00         3\n          12       0.53      1.00      0.69         9\n          13       0.00      0.00      0.00         1\n          14       0.00      0.00      0.00         1\n          15       0.00      0.00      0.00         2\n          16       0.00      0.00      0.00         3\n          17       0.29      1.00      0.44        10\n          18       0.00      0.00      0.00         1\n          19       0.00      0.00      0.00         2\n          20       0.00      0.00      0.00         2\n          21       0.00      0.00      0.00         3\n          22       0.00      0.00      0.00         3\n          23       1.00      1.00      1.00         7\n\n    accuracy                           0.54        72\n   macro avg       0.24      0.25      0.22        72\nweighted avg       0.44      0.54      0.44        72\n\n"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print('True:', y_test)\n",
    "print('Pred:', predicted)\n",
    "print('Score Test:', text_clf.score(X_test, y_test))\n",
    "print('Score Train', text_clf.score(X_train, y_train))\n",
    "\n",
    "print('\\nKlassifikations Report Testdaten:')\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print('\\nKlassifikations Report Trainingsdaten:')\n",
    "print(metrics.classification_report(y_train, text_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "True: [ 8 12  6 23 12 12 12 12]\nPred: [ 8 23  6 23 12  4  7 23]\nTest: 0.5\nTrain 0.9166666666666666\n\nKlassifikations Report Testdaten:\n              precision    recall  f1-score   support\n\n           4       0.00      0.00      0.00         0\n           6       1.00      1.00      1.00         1\n           7       0.00      0.00      0.00         0\n           8       1.00      1.00      1.00         1\n          12       1.00      0.20      0.33         5\n          23       0.33      1.00      0.50         1\n\n    accuracy                           0.50         8\n   macro avg       0.56      0.53      0.47         8\nweighted avg       0.92      0.50      0.52         8\n\n\nKlassifikations Report Trainingsdaten:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         1\n           1       1.00      1.00      1.00         5\n           2       0.50      0.50      0.50         2\n           3       0.00      0.00      0.00         1\n           4       1.00      1.00      1.00         1\n           5       1.00      1.00      1.00         1\n           6       0.20      1.00      0.33         1\n           7       1.00      1.00      1.00         6\n           8       1.00      1.00      1.00         3\n           9       1.00      0.67      0.80         3\n          10       1.00      1.00      1.00         1\n          11       1.00      0.67      0.80         3\n          12       1.00      1.00      1.00         9\n          13       1.00      1.00      1.00         1\n          14       1.00      1.00      1.00         1\n          15       1.00      1.00      1.00         2\n          16       1.00      1.00      1.00         3\n          17       1.00      1.00      1.00        10\n          18       1.00      1.00      1.00         1\n          19       1.00      1.00      1.00         2\n          20       0.67      1.00      0.80         2\n          21       1.00      0.33      0.50         3\n          22       1.00      1.00      1.00         3\n          23       1.00      1.00      1.00         7\n\n    accuracy                           0.92        72\n   macro avg       0.89      0.88      0.86        72\nweighted avg       0.95      0.92      0.92        72\n\n"
    }
   ],
   "source": [
    "text_svm = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_svm.fit(X_train, y_train)\n",
    "predicted = text_svm.predict(X_test)\n",
    "\n",
    "print('True:', y_test)\n",
    "print('Pred:', predicted)\n",
    "print('Test:', text_svm.score(X_test, y_test))\n",
    "print('Train', text_svm.score(X_train, y_train))\n",
    "\n",
    "print('\\nKlassifikations Report Testdaten:')\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print('\\nKlassifikations Report Trainingsdaten:')\n",
    "print(metrics.classification_report(y_train, text_svm.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}